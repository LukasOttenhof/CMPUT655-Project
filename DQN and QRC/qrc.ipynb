{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "401f3e95",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gym has been unmaintained since 2022 and does not support NumPy 2.0 amongst other critical functionality.\n",
      "Please upgrade to Gymnasium, the maintained drop-in replacement of Gym, or contact the authors of your software and request that they upgrade.\n",
      "Users of this version of Gym should be able to simply replace 'import gym' with 'import gymnasium as gym' in the vast majority of cases.\n",
      "See the migration guide at https://gymnasium.farama.org/introduction/migration_guide/ for additional information.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os, shutil\n",
    "from tqdm import tqdm\n",
    "from rl_glue import RLGlue\n",
    "\n",
    "from tbu_gym.tbu_discrete import TruckBackerEnv_D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a5ac72d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8d34881",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tbu_gym.tbu_discrete import TruckBackerEnv_D\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#hyper params, these are set by default in the agent but can be changed here\n",
    "num_episodes = 1000\n",
    "max_steps_per_episode = 500\n",
    "gamma = 0.99\n",
    "learning_rate = 1e-3\n",
    "epsilon_start = 1.0\n",
    "epsilon_decay = 0.99997\n",
    "epsilon_min = 0.01\n",
    "batch_size = 64\n",
    "target_update_freq = 5\n",
    "\n",
    "#agent env setup\n",
    "env = TruckBackerEnv_D(render_mode=None)\n",
    "state_dim = env.observation_space.shape[0]\n",
    "action_dim = env.action_space.n\n",
    "\n",
    "agent = QRCAgent(\n",
    "    state_dim=state_dim,\n",
    "    action_dim=action_dim,\n",
    "    lr=learning_rate,\n",
    "    gamma=gamma,\n",
    "    epsilon=epsilon_start,\n",
    "    epsilon_decay=epsilon_decay,\n",
    "    epsilon_min=epsilon_min,\n",
    "    batch_size=batch_size\n",
    ")\n",
    "\n",
    "#training\n",
    "episode_rewards = []\n",
    "\n",
    "for episode in range(1, num_episodes + 1):\n",
    "    state = env.reset()\n",
    "    total_reward = 0\n",
    "\n",
    "    for t in range(max_steps_per_episode):\n",
    "  \n",
    "        action = agent.agent_policy(state) # e greedy action\n",
    "  \n",
    "        # step env\n",
    "        next_state, reward, done, info = env.step(action) # do a observe s',r and if terminal\n",
    "        total_reward += reward\n",
    "\n",
    "        #store transition in memory\n",
    "        agent.remember(state, action, reward, next_state, done) # set s' = s a r and if terminal\n",
    "\n",
    "        # train agent with memory, will train with batch size set in agent\n",
    "        agent.train_with_mem() \n",
    "\n",
    "        state = next_state #s = s'\n",
    "\n",
    "        if done: # if terminal state\n",
    "            break\n",
    "\n",
    "\n",
    "    if episode % target_update_freq == 0:\n",
    "        agent.update_target()\n",
    "\n",
    "    episode_rewards.append(total_reward)\n",
    "    \n",
    "    print(f\"Episode {episode}, Reward: {total_reward}, Epsilon: {agent.epsilon:.3f}\")\n",
    "\n",
    "\n",
    "plt.plot(episode_rewards)\n",
    "plt.xlabel('Episode')\n",
    "plt.ylabel('Total Reward')\n",
    "plt.title('QRC Training on TruckBackerEnv_D')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
